{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td3efvAADMeo",
        "outputId": "035c3619-8240-4eb8-8ab0-644e972623e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.7/dist-packages (1.4)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.64.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python\n",
        "\n",
        "!pip install ffmpeg moviepy\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTL374hbmXVY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "import moviepy.editor as mp\n",
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMorTmWDt1y5"
      },
      "outputs": [],
      "source": [
        "def find_speaking(audio_clip, window_size=20, volume_threshold=0.0001):\n",
        "\n",
        "    num_windows = math.floor(audio_clip.end/window_size)\n",
        "\n",
        "    window_is_silent = []\n",
        "    for i in range(num_windows):\n",
        "        s = audio_clip.subclip(i * window_size, (i + 1) * window_size)\n",
        "\n",
        "        v = s.max_volume()\n",
        "        window_is_silent.append(v < volume_threshold)\n",
        "\n",
        "    start = 0\n",
        "    end = 0\n",
        "    speaking_intervals = []\n",
        "    for i in range(1, len(window_is_silent)):\n",
        "        if window_is_silent[i - 1] and not window_is_silent[i]:\n",
        "            start = i * window_size\n",
        "\n",
        "        if not window_is_silent[i - 1] and window_is_silent[i]:\n",
        "            end = i * window_size\n",
        "            new_speaking_interval = [start - 0.25, end + 0.25]\n",
        "\n",
        "            need_to_merge = len(speaking_intervals) > 0 and speaking_intervals[-1][1] > new_speaking_interval[0]\n",
        "            if need_to_merge:\n",
        "                merged_interval = [speaking_intervals[-1][0], new_speaking_interval[1]]\n",
        "                speaking_intervals[-1] = merged_interval\n",
        "            else:\n",
        "                element = (new_speaking_interval, new_speaking_interval[1] - new_speaking_interval[0])\n",
        "                speaking_intervals.append(element)\n",
        "\n",
        "    return speaking_intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Grw8coept6SE"
      },
      "outputs": [],
      "source": [
        "def find_longest_speaking_interval(speaking_intervals):    \n",
        "    maximum = max(speaking_intervals, key=itemgetter(1))[0] \n",
        "    return maximum "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHQUvTJKu34q"
      },
      "outputs": [],
      "source": [
        "clip = mp.VideoFileClip('drive/MyDrive/dataset/2022-04-11 14_31 Software Design, лекция, ВШЭ3, весна 2022.mp4')\n",
        "audio = clip.audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCDKJ83Cuxv6"
      },
      "outputs": [],
      "source": [
        "  # longest silence interval in milliseconds\n",
        "result = find_longest_speaking_interval(find_speaking(audio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjTS4s5oUm2c",
        "outputId": "13c019d2-c40d-4f7a-d1d9-e1b4448bb163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[839.75, 5580.25]\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-Fil2eDqLou"
      },
      "outputs": [],
      "source": [
        "def find_shot_transition_start(cap):\n",
        "    threshold = 125\n",
        "\n",
        "  # average intensity of pixels in a frame\n",
        "    last_mean = 0 \n",
        "    start_lection = 0\n",
        "\n",
        "    while True:\n",
        "      #  get the image of current frame\n",
        "        (rv, im) = cap.read()\n",
        "        # if cant get the frame -- break\n",
        "        if not rv:\n",
        "            break\n",
        "        # get mean intensivity of pixels (colors in rgb)\n",
        "        frame_mean = np.sum(im) / float(im.shape[0] * im.shape[1] * im.shape[2])\n",
        "\n",
        "        # check if we reach the start timecode from silence detection\n",
        "        if cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0 >= result[0]:\n",
        "            #  return silence timecode if we not detect shot transition\n",
        "            if start_lection == 0:\n",
        "                return result[0]\n",
        "            break\n",
        "        # check changes of mean intensivity, аnd save timecode\n",
        "        if frame_mean >= threshold and last_mean < threshold:\n",
        "            start_lection = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "\n",
        "        elif frame_mean < threshold and last_mean >= threshold:\n",
        "            start_lection = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "\n",
        "        last_mean = frame_mean\n",
        "\n",
        "    return start_lection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhOmv__rPxGq"
      },
      "outputs": [],
      "source": [
        "def find_shot_transition_end(cap):\n",
        "    threshold = 125\n",
        "  # average intensity of pixels in a frame\n",
        "    last_mean = 0 \n",
        "\n",
        "  # video number of frames (for getting last index) and fps length in seconds\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT) - 2\n",
        "\n",
        "    end_lection = 0\n",
        "\n",
        "    while True:\n",
        "        # set the frame to the video\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
        "        (rv, im) = cap.read()\n",
        "        # run through frames in 4 times fps for quick processing\n",
        "        frame_count = frame_count - 4 * fps\n",
        "\n",
        "        if not rv:\n",
        "            break\n",
        "\n",
        "        frame_mean = np.sum(im) / float(im.shape[0] * im.shape[1] * im.shape[2])\n",
        "\n",
        "        if cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0 <= result[1]:\n",
        "            if end_lection == 0:\n",
        "                return result[1]\n",
        "            break\n",
        "\n",
        "        if frame_mean >= threshold and last_mean < threshold:\n",
        "            end_lection = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "\n",
        "        elif frame_mean < threshold and last_mean >= threshold:\n",
        "            end_lection = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
        "\n",
        "        last_mean = frame_mean\n",
        "        \n",
        "    return end_lection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLPFJf-3l9pv"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('drive/MyDrive/dataset/2022-04-11 14_31 Software Design, лекция, ВШЭ3, весна 2022.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tRUuRofBstlw"
      },
      "outputs": [],
      "source": [
        "\n",
        "correct_answer = [find_shot_transition_start(cap), find_shot_transition_end(cap)]\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZNKzSCZJ9560",
        "outputId": "e70fb5a7-48ee-49a7-ba71-64a8ff0aeef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(580.32, 5580.25)\n"
          ]
        }
      ],
      "source": [
        "print(correct_answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "shot_transition .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}