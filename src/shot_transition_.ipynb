{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shot_transition .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td3efvAADMeo",
        "outputId": "5d0f3ecb-0738-4912-febf-0ace3a4ce235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tTL374hbmXVY"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('downloaded_videos/2022-03-14 14_31 Software Design, лекция, ВШЭ3, весна 2022.mp4')\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "print(\"Video Resolution: %d x %d\" % (width, height))\n",
        "\n",
        "threshold = 125\n",
        "\n",
        "print(\"Detecting scenes with threshold = %d.\\n\" % threshold)\n",
        "\n",
        "last_mean = 0  # Mean intensity of the *last* frame processed.\n",
        "start_time = cv2.getTickCount()  # Used for benchmarking/statistics after loop.\n",
        "\n",
        "while True:\n",
        "    # Get next frame from video.\n",
        "    (rv, im) = cap.read()\n",
        "    if not rv:  # im is a valid image if and only if rv is true\n",
        "        break\n",
        "\n",
        "    # Compute mean intensity of pixels in frame.\n",
        "    frame_mean = np.sum(im) / float(im.shape[0] * im.shape[1] * im.shape[2])\n",
        "    # Dividing the sum by the image size is 35-40% faster than using \n",
        "    # either im.mean() or np.mean(im).\n",
        "\n",
        "    # Detect fade in from black.\n",
        "    if frame_mean >= threshold and last_mean < threshold:\n",
        "        print(\"Detected fade in at %dms (frame %d).\" % (\n",
        "            \n",
        "            cap.get(cv2.CAP_PROP_POS_MSEC),\n",
        "            cap.get(cv2.CAP_PROP_POS_FRAMES)))\n",
        "\n",
        "    # Detect fade out to black.\n",
        "    elif frame_mean < threshold and last_mean >= threshold:\n",
        "        print(\"Detected fade out at %dms (frame %d).\" % (\n",
        "            cap.get(cv2.CAP_PROP_POS_MSEC),\n",
        "            cap.get(cv2.CAP_PROP_POS_FRAMES)))\n",
        "\n",
        "    last_mean = frame_mean  # Store current mean to compare in next iteration.\n",
        "\n",
        "# Get # of frames in video based on the position of the last frame we read.\n",
        "frame_count = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "# Compute runtime and average framerate\n",
        "total_runtime = float(cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
        "avg_framerate = float(frame_count) / total_runtime\n",
        "\n",
        "print(\"Read %d frames from video in %4.2f seconds (avg. %4.1f FPS).\" % (\n",
        "    frame_count, total_runtime, avg_framerate))\n",
        "\n",
        "cap.release()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "DLPFJf-3l9pv",
        "outputId": "c090529b-5bad-4cb0-b8bb-dc8faf4d4df5"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Resolution: 1920 x 1080\n",
            "Detecting scenes with threshold = 125.\n",
            "\n",
            "Detected fade in at 510440ms (frame 12762).\n",
            "Detected fade out at 546000ms (frame 13651).\n",
            "Detected fade in at 546680ms (frame 13668).\n",
            "Detected fade out at 548120ms (frame 13704).\n",
            "Detected fade in at 548720ms (frame 13719).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-00259453a865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Get next frame from video.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# im is a valid image if and only if rv is true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}